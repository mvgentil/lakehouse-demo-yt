# ğŸ—ï¸ Data Lake vs Data Lakehouse â€” Projeto DidÃ¡tico

> ğŸ“¹ Projeto de demonstraÃ§Ã£o para aula no YouTube sobre as diferenÃ§as entre **Data Lake** e **Data Lakehouse**.

## ğŸ¯ Objetivo

Demonstrar na prÃ¡tica a diferenÃ§a entre um **Data Lake** (Parquet puro) e um **Data Lakehouse** (Delta Table), usando o mesmo dataset e as mesmas transformaÃ§Ãµes, permitindo comparar as abordagens lado a lado.

## ğŸ“Š Dataset

**Online Retail Dataset** â€” TransaÃ§Ãµes de uma loja de varejo online do Reino Unido (2010-2011).

- **Fonte**: [Kaggle](https://www.kaggle.com/datasets/vijayuv/online-retail)
- **Registros**: ~541.000 transaÃ§Ãµes
- **Formato original**: CSV

## ğŸ›ï¸ Arquitetura

```
data/
â”œâ”€â”€ raw/                    â† CSV original
â”œâ”€â”€ lake/                   â† Data Lake (Parquet puro)
â”‚   â”œâ”€â”€ 01_bronze/          â† Dados brutos em Parquet
â”‚   â”œâ”€â”€ 02_silver/          â† Dados limpos (Star Schema)
â”‚   â””â”€â”€ 03_gold/            â† AgregaÃ§Ãµes para BI
â””â”€â”€ lakehouse/              â† Data Lakehouse (Delta Table)
    â”œâ”€â”€ 01_bronze/          â† Dados brutos em Delta Table
    â”œâ”€â”€ 02_silver/          â† Dados limpos (Star Schema)
    â””â”€â”€ 03_gold/            â† AgregaÃ§Ãµes para BI
```

### Comparativo

| Feature | Data Lake (Parquet) | Lakehouse (Delta Table) |
|---|---|---|
| Formato | `.parquet` | `.parquet` + `_delta_log/` |
| TransaÃ§Ãµes ACID | âŒ | âœ… |
| Time Travel | âŒ | âœ… |
| Schema Enforcement | âŒ | âœ… |
| Upserts/Merges | Manual | Nativo |

## ğŸ› ï¸ Tech Stack

- **Python 3.13**
- **DuckDB** â€” Motor de consulta SQL local
- **Delta Lake** (`deltalake`) â€” Formato de tabela transacional
- **Pandas / PyArrow** â€” ManipulaÃ§Ã£o de dados
- **Streamlit + Plotly** â€” Dashboard interativo
- **KaggleHub** â€” Download automÃ¡tico do dataset
- **uv** â€” Gerenciador de pacotes

## ğŸš€ Como Rodar

### 1. Instalar dependÃªncias

```bash
uv sync
```

### 2. Baixar o dataset

**OpÃ§Ã£o A** â€” Download automÃ¡tico via KaggleHub:
```bash
uv run src/00_ingest.py
```

**OpÃ§Ã£o B** â€” Download manual:
Baixe o [OnlineRetail.csv](https://www.kaggle.com/datasets/vijayuv/onlineretail) e coloque em `data/raw/`.

### 3. Executar os pipelines

```bash
# Pipeline Data Lake (Parquet)
uv run src/lake_pipeline.py

# Pipeline Data Lakehouse (Delta Table)
uv run src/lakehouse_pipeline.py
```

Ou execute cada camada individualmente:

```bash
# Data Lake
uv run src/lake_01_bronze.py
uv run src/lake_02_silver.py
uv run src/lake_03_gold.py

# Data Lakehouse
uv run src/lakehouse_01_bronze.py
uv run src/lakehouse_02_silver.py
uv run src/lakehouse_03_gold.py
```

### 4. Abrir o Dashboard

```bash
uv run streamlit run src/app.py
```

## ğŸ““ Notebooks de ExploraÃ§Ã£o

Na pasta `notebooks/` vocÃª encontra notebooks interativos para demonstrar:

| Notebook | ConteÃºdo |
|---|---|
| `lake_explorations.ipynb` | ExploraÃ§Ã£o do Data Lake + demonstraÃ§Ã£o das **limitaÃ§Ãµes** |
| `lakehouse_exploration.ipynb` | ExploraÃ§Ã£o do Lakehouse + demonstraÃ§Ã£o das **vantagens** (Time Travel, Schema Enforcement, ACID) |

## ğŸ“ Estrutura do Projeto

```
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/OnlineRetail.csv
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ lake_explorations.ipynb
â”‚   â””â”€â”€ lakehouse_exploration.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ 00_ingest.py              # Download automÃ¡tico (KaggleHub)
â”‚   â”œâ”€â”€ lake_01_bronze.py         # CSV â†’ Parquet
â”‚   â”œâ”€â”€ lake_02_silver.py         # Limpeza + Star Schema (Parquet)
â”‚   â”œâ”€â”€ lake_03_gold.py           # AgregaÃ§Ãµes (Parquet)
â”‚   â”œâ”€â”€ lake_pipeline.py          # Executa todo o pipeline Lake
â”‚   â”œâ”€â”€ lakehouse_01_bronze.py    # CSV â†’ Delta Table
â”‚   â”œâ”€â”€ lakehouse_02_silver.py    # Limpeza + Star Schema (Delta)
â”‚   â”œâ”€â”€ lakehouse_03_gold.py      # AgregaÃ§Ãµes (Delta)
â”‚   â”œâ”€â”€ lakehouse_pipeline.py     # Executa todo o pipeline Lakehouse
â”‚   â””â”€â”€ app.py                    # Dashboard Streamlit
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```
